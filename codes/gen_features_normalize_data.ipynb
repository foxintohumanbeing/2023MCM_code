{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import feature_utils as futils\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Contest number', 'Word', 'Number of reported results',\n",
       "       'Number in hard mode', '1 try', '2 tries', '3 tries', '4 tries',\n",
       "       '5 tries', '6 tries', '7 or more tries (X)', 'Etrial', 'weekday',\n",
       "       'HD_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data\n",
    "word360 = pd.read_excel('../datafeatures_14new_update.xlsx')\n",
    "# print(word360)\n",
    "word360 = word360.loc[:,  word360.columns[2:17] ]\n",
    "word360.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>aback</td>\n",
       "      <td>-1.062652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>abase</td>\n",
       "      <td>-2.136768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>abate</td>\n",
       "      <td>-0.800032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>abbey</td>\n",
       "      <td>0.257638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>abbot</td>\n",
       "      <td>-0.440426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304</th>\n",
       "      <td>2304</td>\n",
       "      <td>young</td>\n",
       "      <td>1.931962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305</th>\n",
       "      <td>2305</td>\n",
       "      <td>youth</td>\n",
       "      <td>1.462069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>2306</td>\n",
       "      <td>zebra</td>\n",
       "      <td>0.076707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>2307</td>\n",
       "      <td>zesty</td>\n",
       "      <td>-1.188668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>2308</td>\n",
       "      <td>zonal</td>\n",
       "      <td>-0.736664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2309 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0   word      freq\n",
       "0              0  aback -1.062652\n",
       "1              1  abase -2.136768\n",
       "2              2  abate -0.800032\n",
       "3              3  abbey  0.257638\n",
       "4              4  abbot -0.440426\n",
       "...          ...    ...       ...\n",
       "2304        2304  young  1.931962\n",
       "2305        2305  youth  1.462069\n",
       "2306        2306  zebra  0.076707\n",
       "2307        2307  zesty -1.188668\n",
       "2308        2308  zonal -0.736664\n",
       "\n",
       "[2309 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2309 = pd.read_csv('../freq_5letters_possiblewords.csv')\n",
    "word2309"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail1 = word360['1 try'].values.astype(np.float64)\n",
    "trail2 = word360['2 tries'].values.astype(np.float64)\n",
    "trail3 = word360['3 tries'].values.astype(np.float64)\n",
    "trail4 = word360['4 tries'].values.astype(np.float64)\n",
    "trail6 = word360['6 tries'].values.astype(np.float64)\n",
    "trail7 = word360['7 or more tries (X)'].values.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_counts = futils.get_double_count(word2309['word'])\n",
    "double_score2309 = []\n",
    "\n",
    "for i in range(len(word2309['word'])):\n",
    "    double_score2309.append( futils.get_double_score(word2309['word'][i], double_counts, threshold=12) )\n",
    "\n",
    "double_score2309 = np.array(double_score2309)\n",
    "\n",
    "double_score360 = []\n",
    "for i in range(len(word360['Word'])):\n",
    "    double_score360.append( futils.get_double_score(word360['Word'][i], double_counts, threshold=12) )\n",
    "\n",
    "double_score360 = np.array(double_score360)\n",
    "double_score360.shape\n",
    "\n",
    "with open('double_counts_2309.pkl', 'wb') as f:\n",
    "    pickle.dump(double_counts, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triple counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trible_counts = futils.get_trible_count(word2309['word'])\n",
    "trible_score2309 = []\n",
    "\n",
    "for i in range(len(word2309['word'])):\n",
    "    trible_score2309.append( futils.get_trible_score(word2309['word'][i], trible_counts, threshold=5) )\n",
    "\n",
    "trible_score2309 = np.array(trible_score2309)\n",
    "\n",
    "trible_score360 = []\n",
    "\n",
    "for i in range(len(word360['Word'])):\n",
    "    trible_score360.append( futils.get_trible_score(word360['Word'][i], trible_counts, threshold=5) )\n",
    "\n",
    "trible_score360 = np.array(trible_score360)\n",
    "trible_score360.shape\n",
    "\n",
    "with open('trible_counts_2309.pkl', 'wb') as f:\n",
    "    pickle.dump(trible_counts, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_counts = futils.get_end_count(word2309['word'])\n",
    "end_score2309 = []\n",
    "\n",
    "for i in range(len(word2309['word'])):\n",
    "    end_score2309.append( futils.get_end_score(word2309['word'][i], end_counts, threshold=10) )\n",
    "\n",
    "end_score2309 = np.array(end_score2309)\n",
    "\n",
    "end_score360 = []\n",
    "\n",
    "for i in range(len(word360['Word'])):\n",
    "    end_score360.append( futils.get_end_score(word360['Word'][i], end_counts, threshold=10) )\n",
    "\n",
    "end_score360 = np.array(end_score360)\n",
    "end_score360.shape\n",
    "\n",
    "with open('end_counts_2309.pkl', 'wb') as f:\n",
    "    pickle.dump(end_counts, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spaced double counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaced_double_counts = futils.get_spaced_double_count(word2309['word'])\n",
    "spaced_double_score2309 = []\n",
    "\n",
    "for i in range(len(word2309['word'])):\n",
    "    spaced_double_score2309.append( futils.get_spaced_double_score(word2309['word'][i], spaced_double_counts, threshold=10) )\n",
    "\n",
    "spaced_double_score2309 = np.array(spaced_double_score2309)\n",
    "\n",
    "spaced_double_score360 = []\n",
    "\n",
    "for i in range(len(word360['Word'])):\n",
    "    spaced_double_score360.append( futils.get_spaced_double_score(word360['Word'][i], spaced_double_counts, threshold=10) )\n",
    "\n",
    "spaced_double_score360 = np.array(spaced_double_score360)\n",
    "spaced_double_score360.shape\n",
    "\n",
    "with open('spaced_double_counts_2309.pkl', 'wb') as f:\n",
    "    pickle.dump(spaced_double_counts, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_counts = futils.get_begin_count(word2309['word'])\n",
    "begin_score2309 = []\n",
    "\n",
    "for i in range(len(word2309['word'])):\n",
    "    begin_score2309.append( futils.get_begin_score(word2309['word'][i], begin_counts, threshold=10) )\n",
    "\n",
    "begin_score2309 = np.array(begin_score2309)\n",
    "\n",
    "begin_score360 = []\n",
    "\n",
    "for i in range(len(word360['Word'])):\n",
    "    begin_score360.append( futils.get_begin_score(word360['Word'][i], begin_counts, threshold=10) )\n",
    "\n",
    "begin_score360 = np.array(begin_score360)\n",
    "begin_score360.shape\n",
    "\n",
    "with open('begin_counts_2309.pkl', 'wb') as f:\n",
    "    pickle.dump(begin_counts, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_counts = futils.get_end_count(word2309['word'])\n",
    "end_score2309 = []\n",
    "\n",
    "for i in range(len(word2309['word'])):\n",
    "    end_score2309.append( futils.get_end_score(word2309['word'][i], end_counts, threshold=10) )\n",
    "\n",
    "end_score2309 = np.array(end_score2309)\n",
    "\n",
    "end_score360 = []\n",
    "\n",
    "for i in range(len(word360['Word'])):\n",
    "    end_score360.append( futils.get_end_score(word360['Word'][i], end_counts, threshold=10) )\n",
    "\n",
    "end_score360 = np.array(end_score360)\n",
    "end_score360.shape\n",
    "\n",
    "with open('end_counts_2309.pkl', 'wb') as f:\n",
    "    pickle.dump(end_counts, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate of letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(359,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_score2309 = []\n",
    "for i in range(len(word2309['word'])):\n",
    "    duplicate_score2309.append( futils.get_duplicate_score(word2309['word'][i]) )\n",
    "\n",
    "duplicate_score2309 = np.array(duplicate_score2309)\n",
    "\n",
    "duplicate_score360 = []\n",
    "for i in range(len(word360['Word'])):\n",
    "    duplicate_score360.append( futils.get_duplicate_score(word360['Word'][i]) )\n",
    "\n",
    "duplicate_score360 = np.array(duplicate_score360)\n",
    "duplicate_score360.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freq of letters (unweighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_count = futils.stats_letter_freq(word2309['word'])\n",
    "freq_score2309 = []\n",
    "\n",
    "for i in range(len(word2309['word'])):\n",
    "    freq_score2309.append( futils.get_freq_score(word2309['word'][i], freq_count) )\n",
    "\n",
    "freq_score2309 = np.array(freq_score2309)\n",
    "\n",
    "freq_score360 = []\n",
    "\n",
    "for i in range(len(word360['Word'])):\n",
    "    freq_score360.append( futils.get_freq_score(word360['Word'][i], freq_count) )\n",
    "\n",
    "freq_score360 = np.array(freq_score360)\n",
    "freq_score360.shape\n",
    "\n",
    "with open('freq_counts_2309.pkl', 'wb') as f:\n",
    "    pickle.dump(freq_count, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freq of letters (weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(359,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_count = futils.stats_letter_freq(word2309['word'])\n",
    "freq_weighted_score2309 = []\n",
    "\n",
    "for i in range(len(word2309['word'])):\n",
    "    freq_weighted_score2309.append( futils.get_freq_score_weighted(word2309['word'][i], freq_count) )\n",
    "\n",
    "freq_weighted_score2309 = np.array(freq_weighted_score2309)\n",
    "\n",
    "freq_weighted_score360 = []\n",
    "\n",
    "for i in range(len(word360['Word'])):\n",
    "    freq_weighted_score360.append( futils.get_freq_score_weighted(word360['Word'][i], freq_count) )\n",
    "\n",
    "freq_weighted_score360 = np.array(freq_weighted_score360)\n",
    "freq_score360.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(359,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_conti_score2309 = []\n",
    "for i in range(len(word2309['word'])):\n",
    "    duplicate_conti_score2309.append( futils.get_duplicate_conti_score(word2309['word'][i]) )\n",
    "\n",
    "duplicate_conti_score2309 = np.array(duplicate_conti_score2309)\n",
    "\n",
    "duplicate_conti_score360 = []\n",
    "for i in range(len(word360['Word'])):\n",
    "    duplicate_conti_score360.append( futils.get_duplicate_conti_score(word360['Word'][i]) )\n",
    "\n",
    "duplicate_conti_score360 = np.array(duplicate_conti_score360)\n",
    "duplicate_conti_score360.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vowel number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(359,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowel_number_score2309 = []\n",
    "for i in range(len(word2309['word'])):\n",
    "    vowel_number_score2309.append( futils.get_vowel_number_score(word2309['word'][i]) )\n",
    "\n",
    "vowel_number_score2309 = np.array(vowel_number_score2309)\n",
    "\n",
    "vowel_number_score360 = []\n",
    "for i in range(len(word360['Word'])):\n",
    "    vowel_number_score360.append( futils.get_vowel_number_score(word360['Word'][i]) )\n",
    "\n",
    "vowel_number_score360 = np.array(vowel_number_score360)\n",
    "vowel_number_score360.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## beginswith vowel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(359,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "begin_vowel_score2309 = []\n",
    "for i in range(len(word2309['word'])):\n",
    "    begin_vowel_score2309.append( futils.get_begin_vowel_score(word2309['word'][i]) )\n",
    "\n",
    "begin_vowel_score2309 = np.array(begin_vowel_score2309)\n",
    "\n",
    "begin_vowel_score360 = []\n",
    "for i in range(len(word360['Word'])):\n",
    "    begin_vowel_score360.append( futils.get_begin_vowel_score(word360['Word'][i]) )\n",
    "\n",
    "begin_vowel_score360 = np.array(begin_vowel_score360)\n",
    "begin_vowel_score360.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## commonality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(359,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commonality_score2309 = word2309['freq']\n",
    "commonality_score360 = np.zeros(len(word360))\n",
    "\n",
    "for i in range(len(word360['Word'])):\n",
    "    commonality_score360[i] = word2309.loc[word2309['word'] == word360['Word'][i]]['freq'].values\n",
    "commonality_score360.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variance of score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(359,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_count = futils.stats_letter_freq(word2309['word'])\n",
    "freq_var_score2309 = []\n",
    "\n",
    "for i in range(len(word2309['word'])):\n",
    "    freq_var_score2309.append( futils.get_freq_var_score(word2309['word'][i], freq_count) )\n",
    "\n",
    "freq_var_score2309 = np.array(freq_var_score2309)\n",
    "\n",
    "freq_var_score360 = []\n",
    "\n",
    "for i in range(len(word360['Word'])):\n",
    "    freq_var_score360.append( futils.get_freq_var_score(word360['Word'][i], freq_count) )\n",
    "\n",
    "freq_var_score360 = np.array(freq_var_score360)\n",
    "freq_var_score360.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the 2309's mean, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [\n",
    "    double_score2309.mean(), \n",
    "    trible_score2309.mean(), \n",
    "    end_score2309.mean(),\n",
    "    spaced_double_score2309.mean(),\n",
    "    begin_score2309.mean(),\n",
    "    # end_score2309.mean(), \n",
    "    duplicate_score2309.mean(), \n",
    "    freq_score2309.mean(), \n",
    "    freq_weighted_score2309.mean(), \n",
    "    duplicate_conti_score2309.mean(), \n",
    "    vowel_number_score2309.mean(), \n",
    "    begin_vowel_score2309.mean(), \n",
    "    commonality_score2309.mean(), \n",
    "    freq_var_score2309.mean()\n",
    "]\n",
    "\n",
    "SIGMA = [\n",
    "    double_score2309.std(), \n",
    "    trible_score2309.std(), \n",
    "    end_score2309.std(),\n",
    "    spaced_double_score2309.std(),\n",
    "    begin_score2309.std(),\n",
    "    # end_score2309.std(), \n",
    "    duplicate_score2309.std(), \n",
    "    freq_score2309.std(), \n",
    "    freq_weighted_score2309.std(), \n",
    "    duplicate_conti_score2309.std(), \n",
    "    vowel_number_score2309.std(), \n",
    "    begin_vowel_score2309.std(), \n",
    "    commonality_score2309.std(), \n",
    "    freq_var_score2309.std()    \n",
    "]\n",
    "\n",
    "with open('../stats2309_14.pkl', 'wb') as f:\n",
    "    pickle.dump((MEAN, SIGMA), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../stats2309_14.pkl', 'rb') as f:\n",
    "    # pickle.dump((MEAN, SIGMA), f)\n",
    "    obj = pickle.load(f)\n",
    "# obj"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output the 360 with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data360 = [\n",
    "    (double_score360 - double_score2309.mean()) / double_score2309.std(),\n",
    "    (trible_score360 - trible_score2309.mean()) / trible_score2309.std(),\n",
    "    (end_score360 - end_score2309.mean()) / end_score2309.std(),\n",
    "    (spaced_double_score360 - spaced_double_score2309.mean()) / spaced_double_score2309.std(), \n",
    "    (begin_score360 - begin_score2309.mean()) / begin_score2309.std(), \n",
    "    # (end_score360 - end_score2309.mean()) / end_score2309.std(),\n",
    "    (duplicate_score360 - duplicate_score2309.mean()) / duplicate_score2309.std(), \n",
    "    (freq_score360 - freq_score2309.mean()) / freq_score2309.std(), \n",
    "    (freq_weighted_score360 - freq_weighted_score2309.mean()) / freq_weighted_score2309.std(), \n",
    "    (duplicate_conti_score360 - duplicate_conti_score2309.mean()) / duplicate_conti_score2309.std(), \n",
    "    (vowel_number_score360 - vowel_number_score2309.mean()) / vowel_number_score2309.std(), \n",
    "    (begin_vowel_score360 - begin_vowel_score2309.mean()) / begin_vowel_score2309.std(), \n",
    "    (commonality_score360 - commonality_score2309.mean()) / commonality_score2309.std(), \n",
    "    (freq_var_score360 - freq_var_score2309.mean()) / freq_var_score2309.std(), \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Contest number</th>\n",
       "      <th>Word</th>\n",
       "      <th>Number of reported results</th>\n",
       "      <th>Number in hard mode</th>\n",
       "      <th>1 try</th>\n",
       "      <th>2 tries</th>\n",
       "      <th>3 tries</th>\n",
       "      <th>4 tries</th>\n",
       "      <th>5 tries</th>\n",
       "      <th>...</th>\n",
       "      <th>spaced double</th>\n",
       "      <th>begin</th>\n",
       "      <th>duplicate</th>\n",
       "      <th>freq</th>\n",
       "      <th>freq weight</th>\n",
       "      <th>dupli conti</th>\n",
       "      <th>vowel num</th>\n",
       "      <th>begin vowel</th>\n",
       "      <th>commonality</th>\n",
       "      <th>freq var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>202</td>\n",
       "      <td>slump</td>\n",
       "      <td>80630</td>\n",
       "      <td>1362</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.389305</td>\n",
       "      <td>2.068445</td>\n",
       "      <td>-0.660634</td>\n",
       "      <td>-1.295936</td>\n",
       "      <td>-0.825135</td>\n",
       "      <td>-0.415544</td>\n",
       "      <td>-1.238871</td>\n",
       "      <td>-0.401105</td>\n",
       "      <td>-0.499057</td>\n",
       "      <td>-1.118001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>203</td>\n",
       "      <td>crank</td>\n",
       "      <td>101503</td>\n",
       "      <td>1763</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.754711</td>\n",
       "      <td>0.406050</td>\n",
       "      <td>-0.660634</td>\n",
       "      <td>-0.274505</td>\n",
       "      <td>-0.244414</td>\n",
       "      <td>-0.415544</td>\n",
       "      <td>-1.238871</td>\n",
       "      <td>-0.401105</td>\n",
       "      <td>-0.060077</td>\n",
       "      <td>0.046649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-09</td>\n",
       "      <td>204</td>\n",
       "      <td>gorge</td>\n",
       "      <td>91477</td>\n",
       "      <td>1913</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026701</td>\n",
       "      <td>-0.420169</td>\n",
       "      <td>1.231927</td>\n",
       "      <td>0.356430</td>\n",
       "      <td>0.036369</td>\n",
       "      <td>-0.415544</td>\n",
       "      <td>0.363680</td>\n",
       "      <td>-0.401105</td>\n",
       "      <td>-0.114883</td>\n",
       "      <td>1.066045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-10</td>\n",
       "      <td>205</td>\n",
       "      <td>query</td>\n",
       "      <td>107134</td>\n",
       "      <td>2242</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.470920</td>\n",
       "      <td>-1.335979</td>\n",
       "      <td>-0.660634</td>\n",
       "      <td>-0.417744</td>\n",
       "      <td>-1.009765</td>\n",
       "      <td>-0.415544</td>\n",
       "      <td>0.363680</td>\n",
       "      <td>-0.401105</td>\n",
       "      <td>1.222267</td>\n",
       "      <td>2.086014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-11</td>\n",
       "      <td>206</td>\n",
       "      <td>drink</td>\n",
       "      <td>153880</td>\n",
       "      <td>3017</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056500</td>\n",
       "      <td>-0.459987</td>\n",
       "      <td>-0.660634</td>\n",
       "      <td>-0.934428</td>\n",
       "      <td>-0.918483</td>\n",
       "      <td>-0.415544</td>\n",
       "      <td>-1.238871</td>\n",
       "      <td>-0.401105</td>\n",
       "      <td>1.189952</td>\n",
       "      <td>-0.471481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>556</td>\n",
       "      <td>condo</td>\n",
       "      <td>20879</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.514107</td>\n",
       "      <td>0.406050</td>\n",
       "      <td>1.231927</td>\n",
       "      <td>-0.586561</td>\n",
       "      <td>-0.501888</td>\n",
       "      <td>-0.415544</td>\n",
       "      <td>0.363680</td>\n",
       "      <td>-0.401105</td>\n",
       "      <td>0.461056</td>\n",
       "      <td>-1.216371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>557</td>\n",
       "      <td>impel</td>\n",
       "      <td>20160</td>\n",
       "      <td>1937</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.283717</td>\n",
       "      <td>-1.226480</td>\n",
       "      <td>-0.660634</td>\n",
       "      <td>0.010268</td>\n",
       "      <td>0.246333</td>\n",
       "      <td>-0.415544</td>\n",
       "      <td>0.363680</td>\n",
       "      <td>2.493116</td>\n",
       "      <td>-1.616356</td>\n",
       "      <td>0.657854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>558</td>\n",
       "      <td>havoc</td>\n",
       "      <td>20001</td>\n",
       "      <td>1919</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.888512</td>\n",
       "      <td>-0.878074</td>\n",
       "      <td>-0.660634</td>\n",
       "      <td>-0.936133</td>\n",
       "      <td>-0.928912</td>\n",
       "      <td>-0.415544</td>\n",
       "      <td>0.363680</td>\n",
       "      <td>-0.401105</td>\n",
       "      <td>-0.183275</td>\n",
       "      <td>0.127703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>559</td>\n",
       "      <td>molar</td>\n",
       "      <td>21204</td>\n",
       "      <td>1973</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.472506</td>\n",
       "      <td>-0.499805</td>\n",
       "      <td>-0.660634</td>\n",
       "      <td>0.624150</td>\n",
       "      <td>0.254274</td>\n",
       "      <td>-0.415544</td>\n",
       "      <td>0.363680</td>\n",
       "      <td>-0.401105</td>\n",
       "      <td>-0.644099</td>\n",
       "      <td>-0.539578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>560</td>\n",
       "      <td>manly</td>\n",
       "      <td>20380</td>\n",
       "      <td>1899</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276304</td>\n",
       "      <td>-0.499805</td>\n",
       "      <td>-0.660634</td>\n",
       "      <td>-0.489363</td>\n",
       "      <td>-0.648392</td>\n",
       "      <td>-0.415544</td>\n",
       "      <td>-1.238871</td>\n",
       "      <td>-0.401105</td>\n",
       "      <td>-0.325188</td>\n",
       "      <td>-0.511495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>359 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Contest number   Word  Number of reported results  \\\n",
       "0   2022-01-07             202  slump                       80630   \n",
       "1   2022-01-08             203  crank                      101503   \n",
       "2   2022-01-09             204  gorge                       91477   \n",
       "3   2022-01-10             205  query                      107134   \n",
       "4   2022-01-11             206  drink                      153880   \n",
       "..         ...             ...    ...                         ...   \n",
       "354 2022-12-27             556  condo                       20879   \n",
       "355 2022-12-28             557  impel                       20160   \n",
       "356 2022-12-29             558  havoc                       20001   \n",
       "357 2022-12-30             559  molar                       21204   \n",
       "358 2022-12-31             560  manly                       20380   \n",
       "\n",
       "     Number in hard mode  1 try  2 tries  3 tries  4 tries  5 tries  ...  \\\n",
       "0                   1362      1        3       23       39       24  ...   \n",
       "1                   1763      1        5       23       31       24  ...   \n",
       "2                   1913      1        3       13       27       30  ...   \n",
       "3                   2242      1        4       16       30       30  ...   \n",
       "4                   3017      1        9       35       34       16  ...   \n",
       "..                   ...    ...      ...      ...      ...      ...  ...   \n",
       "354                 2012      0        2       17       35       29  ...   \n",
       "355                 1937      0        3       21       40       25  ...   \n",
       "356                 1919      0        2       16       38       30  ...   \n",
       "357                 1973      0        4       21       38       26  ...   \n",
       "358                 1899      0        2       17       37       29  ...   \n",
       "\n",
       "     spaced double     begin  duplicate      freq  freq weight  dupli conti  \\\n",
       "0        -0.389305  2.068445  -0.660634 -1.295936    -0.825135    -0.415544   \n",
       "1         0.754711  0.406050  -0.660634 -0.274505    -0.244414    -0.415544   \n",
       "2         0.026701 -0.420169   1.231927  0.356430     0.036369    -0.415544   \n",
       "3        -1.470920 -1.335979  -0.660634 -0.417744    -1.009765    -0.415544   \n",
       "4        -0.056500 -0.459987  -0.660634 -0.934428    -0.918483    -0.415544   \n",
       "..             ...       ...        ...       ...          ...          ...   \n",
       "354      -0.514107  0.406050   1.231927 -0.586561    -0.501888    -0.415544   \n",
       "355      -1.283717 -1.226480  -0.660634  0.010268     0.246333    -0.415544   \n",
       "356      -0.888512 -0.878074  -0.660634 -0.936133    -0.928912    -0.415544   \n",
       "357      -0.472506 -0.499805  -0.660634  0.624150     0.254274    -0.415544   \n",
       "358       0.276304 -0.499805  -0.660634 -0.489363    -0.648392    -0.415544   \n",
       "\n",
       "     vowel num  begin vowel  commonality  freq var  \n",
       "0    -1.238871    -0.401105    -0.499057 -1.118001  \n",
       "1    -1.238871    -0.401105    -0.060077  0.046649  \n",
       "2     0.363680    -0.401105    -0.114883  1.066045  \n",
       "3     0.363680    -0.401105     1.222267  2.086014  \n",
       "4    -1.238871    -0.401105     1.189952 -0.471481  \n",
       "..         ...          ...          ...       ...  \n",
       "354   0.363680    -0.401105     0.461056 -1.216371  \n",
       "355   0.363680     2.493116    -1.616356  0.657854  \n",
       "356   0.363680    -0.401105    -0.183275  0.127703  \n",
       "357   0.363680    -0.401105    -0.644099 -0.539578  \n",
       "358  -1.238871    -0.401105    -0.325188 -0.511495  \n",
       "\n",
       "[359 rows x 28 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_name = ['double', 'trible', 'end', 'spaced double', 'begin', 'duplicate', 'freq', 'freq weight', \n",
    "'dupli conti', 'vowel num', 'begin vowel', 'commonality', 'freq var']\n",
    "\n",
    "for i in range(13):\n",
    "    word360.insert(len(word360.columns), col_name[i], data360[i])\n",
    "word360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Contest number', 'Word', 'Number of reported results',\n",
       "       'Number in hard mode', '1 try', '2 tries', '3 tries', '4 tries',\n",
       "       '5 tries', '6 tries', '7 or more tries (X)', 'Etrial', 'weekday',\n",
       "       'HD_ratio', 'double', 'trible', 'end', 'spaced double', 'begin',\n",
       "       'duplicate', 'freq', 'freq weight', 'dupli conti', 'vowel num',\n",
       "       'begin vowel', 'commonality', 'freq var'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word360.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word360.to_excel('../datafeatures_14_0220a.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output the 2309 with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2309 = [\n",
    "    (double_score2309 - double_score2309.mean()) / double_score2309.std(),\n",
    "    (trible_score2309 - trible_score2309.mean()) / trible_score2309.std(),\n",
    "    (end_score2309 - end_score2309.mean()) / end_score2309.std(),\n",
    "    (spaced_double_score2309 - spaced_double_score2309.mean()) / spaced_double_score2309.std(), \n",
    "    (begin_score2309 - begin_score2309.mean()) / begin_score2309.std(), \n",
    "    # (end_score2309 - end_score2309.mean()) / end_score2309.std(),\n",
    "    (duplicate_score2309 - duplicate_score2309.mean()) / duplicate_score2309.std(), \n",
    "    (freq_score2309 - freq_score2309.mean()) / freq_score2309.std(), \n",
    "    (freq_weighted_score2309 - freq_weighted_score2309.mean()) / freq_weighted_score2309.std(), \n",
    "    (duplicate_conti_score2309 - duplicate_conti_score2309.mean()) / duplicate_conti_score2309.std(), \n",
    "    (vowel_number_score2309 - vowel_number_score2309.mean()) / vowel_number_score2309.std(), \n",
    "    (begin_vowel_score2309 - begin_vowel_score2309.mean()) / begin_vowel_score2309.std(), \n",
    "    (commonality_score2309 - commonality_score2309.mean()) / commonality_score2309.std(), \n",
    "    (freq_var_score2309 - freq_var_score2309.mean()) / freq_var_score2309.std(), \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2309 = word2309.drop('freq', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word</th>\n",
       "      <th>double</th>\n",
       "      <th>trible</th>\n",
       "      <th>end</th>\n",
       "      <th>spaced double</th>\n",
       "      <th>begin</th>\n",
       "      <th>duplicate</th>\n",
       "      <th>freq</th>\n",
       "      <th>freq weight</th>\n",
       "      <th>dupli conti</th>\n",
       "      <th>vowel num</th>\n",
       "      <th>begin vowel</th>\n",
       "      <th>commonality</th>\n",
       "      <th>freq var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>aback</td>\n",
       "      <td>-0.556142</td>\n",
       "      <td>0.117946</td>\n",
       "      <td>-0.833192</td>\n",
       "      <td>-0.243703</td>\n",
       "      <td>-0.171308</td>\n",
       "      <td>1.231927</td>\n",
       "      <td>-0.641129</td>\n",
       "      <td>0.143887</td>\n",
       "      <td>-0.415544</td>\n",
       "      <td>0.363680</td>\n",
       "      <td>2.493116</td>\n",
       "      <td>-1.062421</td>\n",
       "      <td>0.729816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>abase</td>\n",
       "      <td>0.059216</td>\n",
       "      <td>-0.060929</td>\n",
       "      <td>1.432469</td>\n",
       "      <td>2.252331</td>\n",
       "      <td>-0.171308</td>\n",
       "      <td>1.231927</td>\n",
       "      <td>1.427313</td>\n",
       "      <td>1.655823</td>\n",
       "      <td>-0.415544</td>\n",
       "      <td>1.966230</td>\n",
       "      <td>2.493116</td>\n",
       "      <td>-2.136306</td>\n",
       "      <td>0.645603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>abate</td>\n",
       "      <td>0.112726</td>\n",
       "      <td>0.654572</td>\n",
       "      <td>1.432469</td>\n",
       "      <td>2.252331</td>\n",
       "      <td>-0.171308</td>\n",
       "      <td>1.231927</td>\n",
       "      <td>1.531331</td>\n",
       "      <td>1.726820</td>\n",
       "      <td>-0.415544</td>\n",
       "      <td>1.966230</td>\n",
       "      <td>2.493116</td>\n",
       "      <td>-0.799859</td>\n",
       "      <td>0.574448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>abbey</td>\n",
       "      <td>-1.666463</td>\n",
       "      <td>-0.955306</td>\n",
       "      <td>1.007200</td>\n",
       "      <td>-1.304517</td>\n",
       "      <td>-0.171308</td>\n",
       "      <td>1.231927</td>\n",
       "      <td>-0.173896</td>\n",
       "      <td>0.503999</td>\n",
       "      <td>2.406486</td>\n",
       "      <td>0.363680</td>\n",
       "      <td>2.493116</td>\n",
       "      <td>0.257582</td>\n",
       "      <td>1.676600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>abbot</td>\n",
       "      <td>-1.358784</td>\n",
       "      <td>-0.955306</td>\n",
       "      <td>0.193321</td>\n",
       "      <td>-0.867711</td>\n",
       "      <td>-0.171308</td>\n",
       "      <td>1.231927</td>\n",
       "      <td>-0.467195</td>\n",
       "      <td>0.279381</td>\n",
       "      <td>2.406486</td>\n",
       "      <td>0.363680</td>\n",
       "      <td>2.493116</td>\n",
       "      <td>-0.440331</td>\n",
       "      <td>0.009471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304</th>\n",
       "      <td>2304</td>\n",
       "      <td>young</td>\n",
       "      <td>-0.047803</td>\n",
       "      <td>0.475697</td>\n",
       "      <td>-1.361113</td>\n",
       "      <td>-0.722109</td>\n",
       "      <td>-1.564932</td>\n",
       "      <td>-0.660634</td>\n",
       "      <td>-1.304462</td>\n",
       "      <td>-1.199691</td>\n",
       "      <td>-0.415544</td>\n",
       "      <td>0.363680</td>\n",
       "      <td>-0.401105</td>\n",
       "      <td>1.931544</td>\n",
       "      <td>-1.186702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305</th>\n",
       "      <td>2305</td>\n",
       "      <td>youth</td>\n",
       "      <td>-0.422369</td>\n",
       "      <td>0.207384</td>\n",
       "      <td>-0.657218</td>\n",
       "      <td>-0.243703</td>\n",
       "      <td>-1.564932</td>\n",
       "      <td>-0.660634</td>\n",
       "      <td>-0.907144</td>\n",
       "      <td>-0.848755</td>\n",
       "      <td>-0.415544</td>\n",
       "      <td>0.363680</td>\n",
       "      <td>-0.401105</td>\n",
       "      <td>1.461752</td>\n",
       "      <td>-1.140727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>2306</td>\n",
       "      <td>zebra</td>\n",
       "      <td>-0.556142</td>\n",
       "      <td>-0.150367</td>\n",
       "      <td>-1.199804</td>\n",
       "      <td>-0.576507</td>\n",
       "      <td>-1.564932</td>\n",
       "      <td>-0.660634</td>\n",
       "      <td>0.223422</td>\n",
       "      <td>-0.445032</td>\n",
       "      <td>-0.415544</td>\n",
       "      <td>0.363680</td>\n",
       "      <td>-0.401105</td>\n",
       "      <td>0.076691</td>\n",
       "      <td>2.727305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>2307</td>\n",
       "      <td>zesty</td>\n",
       "      <td>0.045839</td>\n",
       "      <td>0.475697</td>\n",
       "      <td>1.007200</td>\n",
       "      <td>0.130702</td>\n",
       "      <td>-1.564932</td>\n",
       "      <td>-0.660634</td>\n",
       "      <td>-0.341009</td>\n",
       "      <td>-0.925931</td>\n",
       "      <td>-0.415544</td>\n",
       "      <td>-1.238871</td>\n",
       "      <td>-0.401105</td>\n",
       "      <td>-1.188411</td>\n",
       "      <td>1.654392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>2308</td>\n",
       "      <td>zonal</td>\n",
       "      <td>0.152858</td>\n",
       "      <td>-0.776431</td>\n",
       "      <td>-0.525238</td>\n",
       "      <td>-1.054914</td>\n",
       "      <td>-1.564932</td>\n",
       "      <td>-0.660634</td>\n",
       "      <td>-0.398986</td>\n",
       "      <td>-0.976740</td>\n",
       "      <td>-0.415544</td>\n",
       "      <td>0.363680</td>\n",
       "      <td>-0.401105</td>\n",
       "      <td>-0.736505</td>\n",
       "      <td>0.472523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2309 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0   word    double    trible       end  spaced double  \\\n",
       "0              0  aback -0.556142  0.117946 -0.833192      -0.243703   \n",
       "1              1  abase  0.059216 -0.060929  1.432469       2.252331   \n",
       "2              2  abate  0.112726  0.654572  1.432469       2.252331   \n",
       "3              3  abbey -1.666463 -0.955306  1.007200      -1.304517   \n",
       "4              4  abbot -1.358784 -0.955306  0.193321      -0.867711   \n",
       "...          ...    ...       ...       ...       ...            ...   \n",
       "2304        2304  young -0.047803  0.475697 -1.361113      -0.722109   \n",
       "2305        2305  youth -0.422369  0.207384 -0.657218      -0.243703   \n",
       "2306        2306  zebra -0.556142 -0.150367 -1.199804      -0.576507   \n",
       "2307        2307  zesty  0.045839  0.475697  1.007200       0.130702   \n",
       "2308        2308  zonal  0.152858 -0.776431 -0.525238      -1.054914   \n",
       "\n",
       "         begin  duplicate      freq  freq weight  dupli conti  vowel num  \\\n",
       "0    -0.171308   1.231927 -0.641129     0.143887    -0.415544   0.363680   \n",
       "1    -0.171308   1.231927  1.427313     1.655823    -0.415544   1.966230   \n",
       "2    -0.171308   1.231927  1.531331     1.726820    -0.415544   1.966230   \n",
       "3    -0.171308   1.231927 -0.173896     0.503999     2.406486   0.363680   \n",
       "4    -0.171308   1.231927 -0.467195     0.279381     2.406486   0.363680   \n",
       "...        ...        ...       ...          ...          ...        ...   \n",
       "2304 -1.564932  -0.660634 -1.304462    -1.199691    -0.415544   0.363680   \n",
       "2305 -1.564932  -0.660634 -0.907144    -0.848755    -0.415544   0.363680   \n",
       "2306 -1.564932  -0.660634  0.223422    -0.445032    -0.415544   0.363680   \n",
       "2307 -1.564932  -0.660634 -0.341009    -0.925931    -0.415544  -1.238871   \n",
       "2308 -1.564932  -0.660634 -0.398986    -0.976740    -0.415544   0.363680   \n",
       "\n",
       "      begin vowel  commonality  freq var  \n",
       "0        2.493116    -1.062421  0.729816  \n",
       "1        2.493116    -2.136306  0.645603  \n",
       "2        2.493116    -0.799859  0.574448  \n",
       "3        2.493116     0.257582  1.676600  \n",
       "4        2.493116    -0.440331  0.009471  \n",
       "...           ...          ...       ...  \n",
       "2304    -0.401105     1.931544 -1.186702  \n",
       "2305    -0.401105     1.461752 -1.140727  \n",
       "2306    -0.401105     0.076691  2.727305  \n",
       "2307    -0.401105    -1.188411  1.654392  \n",
       "2308    -0.401105    -0.736505  0.472523  \n",
       "\n",
       "[2309 rows x 15 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_name = ['double', 'trible', 'end', 'spaced double', 'begin', 'duplicate', 'freq', 'freq weight', \n",
    "'dupli conti', 'vowel num', 'begin vowel', 'commonality', 'freq var']\n",
    "\n",
    "for i in range(len(col_name)):\n",
    "    word2309.insert(len(word2309.columns), col_name[i], data2309[i])\n",
    "word2309"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2309.to_excel('../datafeatures_14_2309_0220a.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ceddf6ad99f59d77d278ce4f0397c6907ff96a12838b0b0961d29304746d9de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
