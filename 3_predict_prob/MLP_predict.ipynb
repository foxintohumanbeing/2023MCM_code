{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "def word_2_onehot(word: str):\n",
    "    assert len(word) == 5, (word, len(word))\n",
    "    # print(word, len(word))\n",
    "    sample = torch.zeros((26*len(word), ))\n",
    "    for i in range(len(word)):\n",
    "        sample[ 26*i + ord(word[i])-97] = 1   \n",
    "    return sample\n",
    "\n",
    "class WordDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        data = pd.read_excel('../UPDATE_Problem_C_Data_Wordle.xlsx')\n",
    "        data = data.to_numpy()[::-1, 1:]\n",
    "        # id, word, num_total, num_hard, 1, 2, 3, 4, 5, 6, X\n",
    "        data[327, 2] = data[326, 2]\n",
    "        self.words = data[:, 1]\n",
    "        self.targets = torch.FloatTensor(data[:, 4:].astype(np.float64)/100)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ''' Return sample(R^130), target R^7 '''\n",
    "        # # index: the data's first element's index\n",
    "        # sample = torch.zeros((130, ))\n",
    "        # # sample[0] = index\n",
    "        # word = self.words[index]\n",
    "        # # print(word)\n",
    "        # for i in range(5):\n",
    "        #     sample[ 26*i + ord(word[i])-97] = 1\n",
    "        sample = word_2_onehot(self.words[index])\n",
    "        target = self.targets[index]\n",
    "        return sample, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.]), tensor([0.0100, 0.0800, 0.3200, 0.3200, 0.1800, 0.0800, 0.0200]))\n"
     ]
    }
   ],
   "source": [
    "dataset = WordDataset()\n",
    "\n",
    "train_size = int(len(dataset) * 0.9)\n",
    "test_size = len(dataset) - train_size\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_set, batch_size, True)\n",
    "test_loader = DataLoader(test_set, 1, False)\n",
    "print(dataset[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(130, 130), nn.BatchNorm1d(130), nn.Dropout(0.3), nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(nn.Linear(130, 64), nn.BatchNorm1d(64), nn.Dropout(0.3), nn.ReLU())\n",
    "        self.layer3 = nn.Sequential(nn.Linear(64, 7), nn.ReLU())\n",
    "        self.softmax = nn.Softmax(1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:10<00:00, 18.78it/s, loss=0.000611]\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = MLP().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "tbar = tqdm(range(num_epochs))\n",
    "\n",
    "model.train()\n",
    "for e in tbar:\n",
    "    batch_loss = []\n",
    "    for sample, target in train_loader:\n",
    "        sample, target = sample.to(device), target.to(device)\n",
    "        # print(sample.shape)\n",
    "        out = model(sample)\n",
    "        loss = criterion(out, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "        batch_loss.append(loss.cpu().item())\n",
    "    \n",
    "    tbar.set_postfix(loss=sum(batch_loss)/len(batch_loss))\n",
    "\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0031317219420290915\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total_loss = []\n",
    "predicted = []\n",
    "gt = []\n",
    "for sample, target in test_loader:\n",
    "    sample, target = sample.to(device), target.to(device)\n",
    "    # print(sample.shape)\n",
    "    out = model(sample)\n",
    "    loss = criterion(out, target)  \n",
    "    total_loss.append(loss.cpu().item())\n",
    "    predicted.append(out.cpu().detach())\n",
    "    gt.append(target.cpu().detach())\n",
    "\n",
    "# print(total_loss)\n",
    "print(np.array(total_loss).mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize the result on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 1\n",
    "for i in range(len(test_loader)):\n",
    "    plt.plot(np.arange(7), predicted[i].numpy().reshape(-1), np.arange(7), gt[i].numpy().reshape(-1))\n",
    "    plt.legend(['predicted', 'gt'])\n",
    "    plt.savefig(f'test/{i}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0152, 0.0684, 0.2122, 0.3041, 0.2541, 0.1300, 0.0159]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = word_2_onehot('eerie')\n",
    "model(test.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ceddf6ad99f59d77d278ce4f0397c6907ff96a12838b0b0961d29304746d9de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
